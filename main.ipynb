{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io import wavfile\n",
    "from tqdm import tqdm\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import logging\n",
    "import warnings\n",
    "from scipy.io.wavfile import WavFileWarning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logger setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"audio_process\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "# Clear existing handlers to avoid duplicates\n",
    "if logger.hasHandlers():\n",
    "    logger.handlers.clear()\n",
    "\n",
    "# File Handler: Write all messages (DEBUG and above) to a log file.\n",
    "fh = logging.FileHandler(\"process.log\", mode='w')\n",
    "fh.setLevel(logging.DEBUG)\n",
    "fh_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "fh.setFormatter(fh_formatter)\n",
    "logger.addHandler(fh)\n",
    "\n",
    "# Console Handler: Only show INFO and above on the console.\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.WARNING)\n",
    "ch_formatter = logging.Formatter('%(message)s')\n",
    "ch.setFormatter(ch_formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "# Ignore metadata from scipy.wavfile\n",
    "warnings.filterwarnings(\"ignore\", category=WavFileWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating and ranking z-vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create overlapping windows (z-vectors)\n",
    "def create_z_vectors(file_path, window_size, hop_size):\n",
    "    \"\"\"\n",
    "    Reads an audio file (WAV or MP3), converts it to mono if needed, and creates\n",
    "    overlapping windows (each of length window_size) using the given hop_size.\n",
    "    For MP3 files, librosa is used; for WAV files, scipy.io.wavfile is used.\n",
    "    \"\"\"\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == '.mp3':\n",
    "        # Load mp3 using librosa.\n",
    "        # sr=None preserves the native sampling rate.\n",
    "        data, sr = librosa.load(file_path, sr=None, mono=True)\n",
    "        logger.info(f\"Processing MP3 '{file_path}' with sample rate: {sr}\")\n",
    "    elif ext == '.wav':\n",
    "        sr, data = wavfile.read(file_path)\n",
    "        logger.info(f\"Processing WAV '{file_path}' with sample rate: {sr}\")\n",
    "        # If stereo, convert to mono by averaging channels.\n",
    "        if data.ndim == 2:\n",
    "            data = data.mean(axis=1)\n",
    "    else:\n",
    "        logger.error(f\"Unsupported file extension: {ext}\")\n",
    "        raise ValueError(f\"Unsupported file extension: {ext}\")\n",
    "\n",
    "    num_samples = len(data)\n",
    "    vectors = []\n",
    "    if hop_size > 0:\n",
    "        num_windows = (num_samples - window_size) // hop_size\n",
    "        for i in range(num_windows):\n",
    "            start = i * hop_size\n",
    "            end = start + window_size\n",
    "            vectors.append(data[start:end])\n",
    "    else:\n",
    "        num_windows = num_samples // window_size\n",
    "        for i in range(num_windows):\n",
    "            start = i * window_size\n",
    "            end = start + window_size\n",
    "            vectors.append(data[start:end])\n",
    "    if num_windows < 1:\n",
    "        logger.error(\"Audio too short for the given window/hop parameters.\")\n",
    "        raise ValueError(\"Audio too short for the given window/hop parameters.\")\n",
    "    return np.array(vectors)\n",
    "\n",
    "\n",
    "# 2. Compute ordinal patterns (ranking)\n",
    "def rank_vector(z):\n",
    "    \"\"\"\n",
    "    Returns the ordinal ranking of the values in vector z.\n",
    "    (Smallest value gets rank 1, next smallest 2, etc.)\n",
    "    \"\"\"\n",
    "    return np.argsort(z).argsort() + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shannon entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Shannon entropy (raw)\n",
    "def compute_shannon_entropy(probabilities):\n",
    "    \"\"\"\n",
    "    Computes Shannon entropy (in bits) given a probability vector.\n",
    "    Ignores zero probabilities.\n",
    "    \"\"\"\n",
    "    probs = probabilities[probabilities > 0]\n",
    "    return -np.sum(probs * np.log2(probs))\n",
    "\n",
    "\n",
    "# 4. Get the observed probability distribution over unique ordinal patterns\n",
    "def row_probabilities_unique(ranked_z_vectors):\n",
    "    \"\"\"\n",
    "    Given an array of ranked z-vectors (each row is one window's ordinal pattern),\n",
    "    returns:\n",
    "      - probabilities: 1D array of the probability (frequency) of each unique pattern.\n",
    "      - unique_patterns: 2D array where each row is a unique ordinal pattern.\n",
    "    \"\"\"\n",
    "    unique_patterns, counts = np.unique(ranked_z_vectors, axis=0, return_counts=True)\n",
    "    probabilities = counts / np.sum(counts)\n",
    "    return probabilities, unique_patterns\n",
    "\n",
    "\n",
    "# 5. Map an ordinal pattern to an index (using Lehmer code)\n",
    "def permutation_to_index(perm):\n",
    "    \"\"\"\n",
    "    Given a permutation (tuple) of length n (with values 1..n),\n",
    "    returns its index in lexicographic order (0-indexed).\n",
    "    (This is a simple Lehmer-code mapping.)\n",
    "    \"\"\"\n",
    "    n = len(perm)\n",
    "    # Convert from 1-indexed to 0-indexed:\n",
    "    perm = [p - 1 for p in perm]\n",
    "    index = 0\n",
    "    for i in range(n):\n",
    "        # Count how many of the remaining entries are smaller than perm[i]\n",
    "        smaller = sum(1 for j in range(i + 1, n) if perm[j] < perm[i])\n",
    "        index += smaller * math.factorial(n - i - 1)\n",
    "    return index\n",
    "\n",
    "\n",
    "# 6. Normalized permutation entropy\n",
    "def compute_normalized_permutation_entropy(probabilities, embedding_dim):\n",
    "    \"\"\"\n",
    "    Normalizes the permutation entropy by the theoretical maximum,\n",
    "    which is log2(embedding_dim!).\n",
    "    Returns a tuple: (H_norm, H_raw, H_max)\n",
    "    \"\"\"\n",
    "\n",
    "    M_possible = math.factorial(embedding_dim)\n",
    "    H_raw = compute_shannon_entropy(probabilities)\n",
    "    H_max = math.log2(M_possible)\n",
    "    return H_raw / H_max, H_raw, H_max\n",
    "\n",
    "\n",
    "# 7. Build the full probability vector (of length m!).\n",
    "#    For unobserved patterns, the probability is 0.\n",
    "def compute_extended_probability_vector(probabilities, unique_patterns, embedding_dim):\n",
    "    M_possible = math.factorial(embedding_dim)\n",
    "    p_extended = np.zeros(M_possible)\n",
    "    # Fill in the observed probabilities by mapping each observed pattern to an index.\n",
    "    for prob, pattern in zip(probabilities, unique_patterns):\n",
    "        idx = permutation_to_index(tuple(pattern))\n",
    "        p_extended[idx] = prob\n",
    "    return p_extended\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JSD and complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Jensen–Shannon divergence between two distributions\n",
    "def compute_js_divergence(p, p_u):\n",
    "    \"\"\"\n",
    "    Computes the Jensen–Shannon divergence between distributions p and p_u.\n",
    "    p and p_u must be vectors of the same length.\n",
    "    \"\"\"\n",
    "    m = 0.5 * (p + p_u)\n",
    "    return compute_shannon_entropy(m) - 0.5 * compute_shannon_entropy(p) - 0.5 * compute_shannon_entropy(p_u)\n",
    "\n",
    "\n",
    "# 9. Normalized JS divergence (disequilibrium)\n",
    "def compute_normalized_js_divergence(p_extended, embedding_dim):\n",
    "    \"\"\"\n",
    "    Computes the JS divergence between the observed (extended) distribution\n",
    "    and the uniform distribution over all m! states, then normalizes it by\n",
    "    a theoretical maximum.\n",
    "    \n",
    "    The theoretical maximum (Q_max) is given by:\n",
    "      Q_max = -0.5 * [ ((M+1)/M)*log2(M+1) - 2*log2(2*M) + log2(M) ]\n",
    "    where M = factorial(embedding_dim)\n",
    "    \"\"\"\n",
    "    M_possible = math.factorial(embedding_dim)\n",
    "    p_u = np.ones(M_possible) / M_possible\n",
    "    JS = compute_js_divergence(p_extended, p_u)\n",
    "    Q_max = -0.5 * (((M_possible + 1) / M_possible) * np.log2(M_possible + 1)\n",
    "                    - 2 * np.log2(2 * M_possible)\n",
    "                    + np.log2(M_possible))\n",
    "    return JS / Q_max if Q_max > 0 else 0.0, JS, Q_max\n",
    "\n",
    "\n",
    "# 10. Complexity measure: here we simply multiply the two normalized measures.\n",
    "def complexity_measure(H_norm, JS_norm):\n",
    "    return H_norm * JS_norm\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11. Process a single audio file to compute H_norm and Complexity\n",
    "def process_audio(file_path, window_size=10, hop_size=5):\n",
    "    # 1. Get overlapping windows (z-vectors)\n",
    "    z_vectors = create_z_vectors(file_path, window_size, hop_size)\n",
    "    \n",
    "    # 2. Compute ordinal (ranking) pattern for each window\n",
    "    ranked_z_vectors = np.array([rank_vector(z) for z in z_vectors])\n",
    "    \n",
    "    # 3. Compute the probability distribution over the observed unique patterns\n",
    "    probabilities, unique_patterns = row_probabilities_unique(ranked_z_vectors)\n",
    "    # print(\"Number of unique ordinal patterns (observed):\", len(probabilities))\n",
    "    \n",
    "    # 4. Compute the normalized permutation entropy (using the theoretical maximum)\n",
    "    H_norm, H_raw, H_max = compute_normalized_permutation_entropy(probabilities, window_size)\n",
    "    \n",
    "    # 5. Extend the observed distribution to the full space of m! outcomes\n",
    "    p_extended = compute_extended_probability_vector(probabilities, unique_patterns, window_size)\n",
    "    \n",
    "    # 6. Compute the normalized JS divergence (disequilibrium)\n",
    "    JS_norm, JS, Q_max = compute_normalized_js_divergence(p_extended, window_size)\n",
    "    \n",
    "    # 7. Compute complexity as the product of the two normalized measures\n",
    "    comp = complexity_measure(H_norm, JS_norm)\n",
    "    \n",
    "    logger.debug(f\"File: {file_path}\")\n",
    "    logger.debug(f\"Embedding dimension (window size): {window_size}\")\n",
    "    logger.debug(f\"Total possible patterns (m!): {math.factorial(window_size)}\")\n",
    "    logger.debug(f\"H_raw: {H_raw}, H_max: {H_max}, Normalized Entropy: {H_norm}\")\n",
    "    logger.debug(f\"JS raw: {JS}, Q_max: {Q_max}, Normalized JS Divergence: {JS_norm}\")\n",
    "    logger.debug(f\"Complexity: {comp}\")\n",
    "    logger.debug(\"-\" * 50)\n",
    "    \n",
    "    return H_norm, comp\n",
    "\n",
    "\n",
    "# 12. Process multiple files and scatter plot all points\n",
    "def process_folder(folder_path, window_size=10, hop_size=5):\n",
    "    \"\"\"\n",
    "    Processes all WAV and MP3 files in the given folder and returns lists of\n",
    "    normalized entropy and complexity for each file.\n",
    "    \"\"\"\n",
    "    # Include both .wav and .mp3 files.\n",
    "    wav_files = glob.glob(os.path.join(folder_path, \"*.wav\"))\n",
    "    mp3_files = glob.glob(os.path.join(folder_path, \"*.mp3\"))\n",
    "    all_files = wav_files + mp3_files\n",
    "    \n",
    "    if not all_files:\n",
    "        logger.info(f\"No audio files found in {folder_path}\")\n",
    "        return [], [], []\n",
    "    \n",
    "    all_H = []\n",
    "    all_comp = []\n",
    "    file_labels = []\n",
    "    \n",
    "    # Use tqdm to add a progress bar over the file list.\n",
    "    for file_path in tqdm(all_files, desc=f\"Processing audio files in {folder_path} with dim {window_size} and hop {hop_size}\"):\n",
    "        try:\n",
    "            H_norm, comp = process_audio(file_path, window_size, hop_size)\n",
    "            all_H.append(H_norm)\n",
    "            all_comp.append(comp)\n",
    "            file_labels.append(os.path.basename(file_path))\n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error processing file {file_path}: {e}\")\n",
    "    \n",
    "    return all_H, all_comp, file_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(folder_path, start, end, grid, folder = \"plots\"):\n",
    "    logger.info(f\"Processing folder {folder_path}\")\n",
    "    # (window sizes 5 to 10)\n",
    "    iterations = list(range(start, end))\n",
    "    n_iter = len(iterations)\n",
    "\n",
    "    # For 2x3 grid\n",
    "    n_cols = grid\n",
    "    n_rows = math.ceil(n_iter / n_cols)\n",
    "\n",
    "    # Create a combined Plotly figure with subplots.\n",
    "    combined_fig = make_subplots(\n",
    "        rows=n_rows,\n",
    "        cols=n_cols,\n",
    "        subplot_titles=[f\"Dim = '{i}', Hop = '{i-1}'\" for i in iterations]\n",
    "    )\n",
    "\n",
    "    iteration_index = 0\n",
    "    for i in iterations:\n",
    "        window_size = i\n",
    "        hop_size = i - 1\n",
    "\n",
    "        # Process the folder to obtain entropy & complexity values.\n",
    "        all_H, all_comp, file_labels = process_folder(folder_path, window_size, hop_size)\n",
    "        df = pd.DataFrame({\n",
    "            \"Normalized Permutation Entropy\": all_H,\n",
    "            \"Normalized Complexity\": all_comp,\n",
    "            \"File\": file_labels\n",
    "        })\n",
    "\n",
    "        trace = go.Scatter(\n",
    "            x=df[\"Normalized Permutation Entropy\"],\n",
    "            y=df[\"Normalized Complexity\"],\n",
    "            mode=\"markers\",\n",
    "            marker=dict(color=df[\"Normalized Complexity\"],\n",
    "                        colorscale=\"hot\",\n",
    "                        size=10),\n",
    "            text=df[\"File\"],\n",
    "            hovertemplate=(\n",
    "                \"Entropy: %{x}<br>\" +\n",
    "                \"Complexity: %{y}<br>\" +\n",
    "                \"File: %{text}<extra></extra>\"\n",
    "            ),\n",
    "            name=f\"Dim = {window_size}, Hop = {hop_size}\",\n",
    "            showlegend=True \n",
    "        )\n",
    "        # Determine subplot row and column indices.\n",
    "        row = iteration_index // n_cols + 1\n",
    "        col = iteration_index % n_cols + 1\n",
    "        combined_fig.add_trace(trace, row=row, col=col)\n",
    "        iteration_index += 1\n",
    "\n",
    "\n",
    "        # Matplotlib plot.\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.scatter(df[\"Normalized Permutation Entropy\"],\n",
    "                    df[\"Normalized Complexity\"],\n",
    "                    s=70,\n",
    "                    c='blue',\n",
    "                    edgecolors='black')\n",
    "        plt.xlabel(\"Normalized Permutation Entropy\")\n",
    "        plt.ylabel(\"Normalized Complexity\")\n",
    "        plt.title(f\"Entropy–Complexity for {folder_path}\\nDim = '{window_size}', Hop = '{hop_size}'\")\n",
    "        plt.xlim(0, 1)\n",
    "        plt.ylim(0, 1)\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        output_dir = f\"{folder}/{os.path.basename(folder_path)}\"\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        output_file = os.path.join(output_dir, f\"entropy_complexity_{os.path.basename(folder_path)}_dim_{window_size}_hop_{hop_size}.png\")\n",
    "        plt.savefig(output_file)\n",
    "        plt.close()\n",
    "        logger.info(f\"Saved Matplotlib plot to {output_file}\")\n",
    "\n",
    "    # Finalize the combined Plotly figure.\n",
    "    combined_fig.update_layout(\n",
    "        width=1200,\n",
    "        height=1600,\n",
    "        title_text=f\"Combined Entropy–Complexity Plots for Folder {folder_path}\",\n",
    "        template=\"plotly_dark\"\n",
    "    )\n",
    "\n",
    "    for axis in combined_fig.layout:\n",
    "        if axis.startswith(\"xaxis\"):\n",
    "            combined_fig.layout[axis].update(range=[0, 1])\n",
    "        if axis.startswith(\"yaxis\"):\n",
    "            combined_fig.layout[axis].update(range=[0, 1])\n",
    "            \n",
    "    combined_fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/smalltest\"\n",
    "start = 5\n",
    "end = 10\n",
    "grid = 2\n",
    "folder = \"plots\"\n",
    "plot_graph(folder_path, start, end, grid, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/genres_30sec/blues\"\n",
    "start = 5\n",
    "end = 10\n",
    "grid = 2\n",
    "folder = \"plots\"\n",
    "plot_graph(folder_path, start, end, grid, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/genres_30sec/classical\"\n",
    "start = 5\n",
    "end = 10\n",
    "grid = 2\n",
    "folder = \"plots\"\n",
    "plot_graph(folder_path, start, end, grid, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/genres_30sec/country\"\n",
    "start = 5\n",
    "end = 10\n",
    "grid = 2\n",
    "folder = \"plots\"\n",
    "plot_graph(folder_path, start, end, grid, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/genres_30sec/disco\"\n",
    "start = 5\n",
    "end = 10\n",
    "grid = 2\n",
    "folder = \"plots\"\n",
    "plot_graph(folder_path, start, end, grid, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hiphop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/genres_30sec/hiphop\"\n",
    "start = 5\n",
    "end = 10\n",
    "grid = 2\n",
    "folder = \"plots\"\n",
    "plot_graph(folder_path, start, end, grid, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jazz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/genres_30sec/jazz\"\n",
    "start = 5\n",
    "end = 10\n",
    "grid = 2\n",
    "folder = \"plots\"\n",
    "plot_graph(folder_path, start, end, grid, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/genres_30sec/metal\"\n",
    "start = 5\n",
    "end = 10\n",
    "grid = 2\n",
    "folder = \"plots\"\n",
    "plot_graph(folder_path, start, end, grid, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/genres_30sec/pop\"\n",
    "start = 5\n",
    "end = 10\n",
    "grid = 2\n",
    "folder = \"plots\"\n",
    "plot_graph(folder_path, start, end, grid, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reggae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/genres_30sec/reggae\"\n",
    "start = 5\n",
    "end = 10\n",
    "grid = 2\n",
    "folder = \"plots\"\n",
    "plot_graph(folder_path, start, end, grid, folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"data/genres_30sec/rock\"\n",
    "start = 5\n",
    "end = 10\n",
    "grid = 2\n",
    "folder = \"plots\"\n",
    "plot_graph(folder_path, start, end, grid, folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
